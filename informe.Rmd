---
title: "Trabajo final Muestreo II"
author: "Fiorella Lúngaro, Emanuelle Marsella y Maximiliano Saldaña"
date: "Diciembre 2021"
output: 
 bookdown::pdf_document2:
    toc: no
    number_sections: false
header-includes:
  - \usepackage{float}
  - \usepackage[spanish]{babel}
editor_options: 
  chunk_output_type: console
---

\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  include = TRUE,
  warning = FALSE,
  out.width = '80%',
  fig.align="center"
  )
```

```{r librerias, include=FALSE}

library(tidyverse)
library(srvyr)
library(survey)
library(PracTools)
library(readxl)
library(tidymodels)
```

# Parte 1

```{r}
# Carga la muestra
muestra <- read_xlsx("datos/muestra grupo 2.xlsx")

# Convertir las variables categóricas a su formato correspondiente
muestra <- muestra %>% 
  mutate(across(where(is.double) & !c(ingreso, w0, edad, R), as.factor))

muestra <- muestra %>% mutate(edad = cut(edad, breaks=c(0, 14,20,25,30,40,50,60,Inf), right = FALSE))

```

Se calculan las estimaciones puntuales de la tasa de desempleo, la proporción de personas pobres y del ingreso promedio, haciendo uso de los ponderadores originales $w_0$, es decir, sin ajustar por no respuesta. Esta estrategia de cómputo resulta correcta si el esquema de no respuesta que se considera es *Missing Completely at Random* (MCAR), bajo el cual la probabilidad de responder no depende de las variables de interés ni auxiliares y todas las unidad del marco tienen la misma probabilidad de responder (Ferreira y Zoppolo, 2017).

```{r}
# Diseño usando los ponderadores originales, MCAR.
##FPC?
design1 <- muestra %>%
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w0)
```

```{r}
## Tasa de desempleo (desempleados/activos)

#REVISAR ESTO
#Se piensa como un problema de estimación en dominios, nos interesan los desempleados considerando el grupo de los activos.
design1 %>% 
  filter(activo == 1) %>% 
  group_by(desocupado) %>% 
  summarise(tasa_desempleo = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

La estimación puntual de la proporción de desempleados es 0,0824; mientras que el error estándar (la medida que empleamos para medir la variación del estimador entre muestra y muestra) es 0,0033. Otra medida de la calidad de un estimador $\hat{\theta}$ es su coeficiente de variación, que mide su dispersi\'on relativa. Se define como (Zoppollo, x):

$$CV(\hat{\theta}) = \frac{\sqrt{\hat{V}(\hat{\theta})}}{\left|E(\hat{\theta})\right|}$$
Y en el caso del estimador de la proporción de desempleados su estimación es 0,04.
El efecto diseño es una medida que permite comparar la eficiencia en términos de variabilidad del estimador para el diseño utilizado, respecto al diseño aleatorio simple sin reposición que. Siendo $p(s)$ el diseño medible considerado, se define como:

$$Deff(p(s), \hat{\theta}) = \frac{V_{p(s)}(\hat{\theta})}{V_{SI}(\hat{\theta})}$$
En el caso del estimador de la proporción de desempleados su valor es 1,07; lo que indica que en este caso el diseño SI es un 7% más eficiente que el empleado.

```{r}
## Proporción de personas pobres
design1 %>% 
  group_by(pobreza) %>% 
  summarise(prop_pobres = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

En cuanto a la proporción de personas pobres, la estimación puntual es de 0,0811. El error estándar se estima que es 0,004 aproximadamente, mientras que el coeficiente de variación se estima que es 0,05 aproximadamente. La estimación del efecto diseño es 2,84; un elevado valor que indica que el diseño empleado es altamente ineficiente en comparación con el SI, en particular casi tres veces más. 

```{r}
## Ingreso promedio
design1 %>% 
  summarise(ingreso_prom = survey_mean(ingreso, deff = TRUE, vartype = c('se','cv')))
```

La estimación puntual del ingreso promedio es 21799, siendo la estimación de su error estándar 240. Por otro lado, el coeficiente de variación toma el valor 0,011. La estimación del efecto diseño es 0,94 aproximadamente, por lo que en este caso el diseño empelado resulta más eficiente que el SI, un 6% más.  

```{r}
muestra %>% 
  summarise(
    # tasa de no respuesta no ponderada
    nr_np = 1 - mean(R),
    # tasa de no respuesta ponderada
    nr_p = 1 - weighted.mean(R, w0))

summary(muestra$w0)

#considerando por estratos

muestra %>% 
  group_by(estrato) %>% 
  summarise(
    # tasa de no respuesta no ponderada
    nr_np = mean(R),
    # tasa de no respuesta ponderada
    nr_p = weighted.mean(R, w0))

#considerando por departamento

muestra %>% 
  group_by(dpto) %>% 
  summarise(
   # tasa de no respuesta no ponderada
    nr_np = mean(R),
    # tasa de no respuesta ponderada
    nr_p = weighted.mean(R, w0))

#considerando por departamento

muestra %>% 
  group_by(edad) %>% 
  summarise(
   # tasa de no respuesta no ponderada
    nr_np = mean(R),
    # tasa de no respuesta ponderada
    nr_p = weighted.mean(R, w0))
```

La tasa de no respuesta no ponderada es del 47,4% mientras que la ponderada es del 47,6%. El hecho de que ambas tasas de no respuesta sean similares puede deberse a que los pesos $w_0$ no son muy disímiles entre sí, siendo su mínimo 104,4; su media 125.6 y su máximo 162. Al considerar la proporción de no respondentes por estrato se puede apreciar que ocurre lo mismo. En este caso se puede observar que la tasa de no respuesta varía según el estrato considerado, siendo el primero (Montevideo bajo) el que cuenta con la mayor tasa, del 56%, y el doceavo el que cuenta con la menor, del 46%. Estas diferencias se ven reflejadas también al considerar la tasa de no respondentes por departamento. Resultan bastante diferentes las tasas de no respuesta considerando los distintos segmentos de edad, el de 0 a 14 años y el de 60 en adelante son los que presentan menor tasa de no respuesta, siendo las de los primeros 50% (no ponderada) y 49% (ponderada) y 50% (no ponderada y ponderada) la de los segundos. 

# Parte 2

## Ajuste por no respuesta por medio de post-estratos de no respuesta

Bajo el enfoque de no respuesta considerado, el MAR (*Missing at Random*), se trabaja bajo el supuesto de que la no respuesta no depende de las variables de interés, pero sí es completamente explicada por variables auxiliares. Lo que se puede hacer en este caso es construir un modelo de respuesta basado en la información auxiliar (Ferreira y Zoppolo, ). 

Siguiendo este enfoque, una manera de realizar el ajuste es mediante clases de no respuesta, creadas en base a información de las unidades presente en el marco muestral. Se crean $g$ clases y se asume que todas las unidades dentro de cada una de ellas tiene la misma probabilidad de responder, cuya fórmula es:

$$\hat{\phi}_{i,g} = TR_w = \frac{\sum_{i \in R}w_i}{\sum_{i \in s}w_i}, \,\,\,\, i \in g$$
Luego, los ponderadores por no respuesta son: 

$$w_i^{nr} = \frac{1}{\pi_i \times \hat{\phi}_{i,g}}$$
($\pi_i$ son las probabilidad de inclusión originales)

En nuestro caso, la información que podríamos emplear que se encuentra en el marco son los estratos. 

```{r}
ggplot(muestra, aes(x=ingreso, y=estrato))+ geom_boxplot()

# Parecería que el estrato permitiría explicar mejor el ingreso
```

```{r}
ajuste_nr_estrato <-  muestra %>% 
  group_by(estrato) %>% 
  summarise(
    tr = mean(R), 
    tr_w = weighted.mean(R, w0))

muestra <- left_join(muestra , select(ajuste_nr_estrato, estrato, tr_w)) %>%
                mutate(w_nr_post = w0/tr_w)  
```


```{r}
ggplot(muestra) +
 geom_point(aes(w0, w_nr_post, color = estrato))

# los ponderadores originales se ven bastante alterados
```


Una medida global frecuentemente utilizada conocida como efecto diseño debido a la
ponderación o efecto de Kish (Kish, 1965, 1992) y representa el incremento en la variabilidad de los
estimadores por usar ponderadores distintos respecto al uso de el mismo ponderador para todos los
caso y se define como uno más la varianza relativa de los ponderadores,


Una forma de medir la variabilidad global de los ponderadores (que en caso de ser alta puede resultar en una variabilidad alta de los estimadores) es el efecto diseño de Kish, que representa el incremento en la variabilidad de los estimadores causada por usar ponderadores distintos para las unidades de la muestra con respecto a usar el mismo ponderador. Su fórmula es:

$$deff_w = 1 + \frac{1}{n} \frac{\sum_s(w_k - \bar{w})^2}{\bar{w}^2}$$

donde $\bar{w} = n^{-1} \sum_sw_k$ es el promedio de los ponderadores.

La práctica usual es calcularlo luego de realizar cada ajuste a los estimadores (no respuesta, calibración, en el caso de este trabajo). Se usa la regla empírica que $deff_w > 1,5$ indican que hay valores extremos de los ponderadores que repercuten en los finales.

```{r}
# Efecto diseño de Kish
deffK(muestra$w_nr_post)

# Ver si solo se calcula con los respondentes
deffK_w_nr_post <- deffK(muestra %>% 
        filter(R ==1) %>%
        select(w_nr_post) %>% 
        pull())
deffK_w_nr_post
```

En nuestro caso, luego de realizar el ajuste por no respuesta $deff_w \simeq 1,033 < 1,5$, por lo que parecería que no resultó en valores extremos de los ponderadores que repercutirían en la variabilidad de los estimadores. 

```{r}
#estimaciones empleando ajuste por no respuesta mediante clases de no respuesta

design2 <- muestra %>%
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w_nr_post)

# Tasa de desempleo
design2 %>% 
  filter(activo == 1) %>% 
  group_by(desocupado) %>% 
  summarise(tasa_desempleo = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

Una vez se realiza el ajuste por no respuesta mediante clases de no respuesta, la estimación puntual de la tasa de desempleo cambia, pasa de 8,24% a 8,31%. El desvío disminuye, pasando de 0,0033 a 0,00336; lo mismo ocurre con el coeficiente de variación, pasando de 0,04 a 0,0404. El efecto diseño pasa de 1,07 a 1,09.

```{r}
## Proporción de personas pobres
design2 %>% 
  group_by(pobreza) %>% 
  summarise(prop_pobres = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

En cuanto a la estimación de la proporción de personas pobres, ahora aumenta de 0,0811 a 0,0837. La estimación del error estándar aumenta a 0,00389, mientras que el coeficiente de vairación no presenta cambio al corregir por no respuesta. El efecto diseño presenta un aumento, de 2,84 a 2,92. 

```{r}
## Ingreso promedio
design2 %>% 
  summarise(ingreso_prom = survey_mean(ingreso, deff = TRUE, vartype = c('se','cv')))
```

La estimación puntual del ingreso promedio disminuye, de 21799 a 21686, el error estándar presenta una disminución en una unidad. El coeficiente de variación con y sin ajuste son iguales hasta 4 lugares después de la coma, mientras que el efecto diseño presenta una leve disminución; pasa de 0,9355 a 0,9314.

## Estimación de propensiones simples de responder utilizando el algoritmo random forest.

El ajuste por propensiones simples consiste en:

$$w_i^{nr} = \frac{1}{\pi_i \times \hat{\phi}_i}$$
donde $\hat{\phi}_i$ es la propensión a responder de la unidad $i$, la cual se estima a partir de un modelo o un algoritmo, haciendo uso de variables auxiliares conocidas tanto para respondentes como no respondentes.

El algoritmo elegido es *Random Forest* (RF), un método no paramétrico mediante el cual se hace uso de múltiples árboles de decisión para obtener una estimación de la propensión a responder de cada individuo a partir de alguna medida de resumen de la clasificación que hacen los árboles (por ejemplo el modo o la media). 

```{r}
# modelamos la no respuesta con random forest
modelo_rf <-  rand_forest(trees = 100) %>% 
  set_engine("ranger") %>% 
  set_mode("classification") %>% 
  fit(as.factor(R) ~ estrato + sexo + edad + dpto, data = muestra)
```

```{r}
# Para ver que tan bien predice el algoritmo
pred_rf <- tibble(predict(modelo_rf, muestra, type= "prob"), predict(modelo_rf, muestra) )

conf_mat(data = bind_cols(select(muestra, R), select(pred_rf, .pred_class)), 
         truth = R, 
         estimate = .pred_class)
```

El modelo predice correctamente al 57% de los no respondentes y al 67% de los respondentes.

```{r}
# Agregamos las propensiones estimadas con random forest a la muestra
pred_rf <-  pred_rf %>% rename(prop_rf = .pred_1)

muestra <-  muestra %>% bind_cols(select(pred_rf, prop_rf))

# Calculamos los ponderadores ajustados por no respuesta usando las propensiones de arriba
muestra <-  muestra %>% 
  mutate(w_nr_rf = w0/prop_rf)
```

```{r}
# Calculamos el efecto diseño de Kish
deffK(muestra$w_nr_rf)

### VER SI SE CALCULA SOLO CON RESPONDENTES
deffK_w_nr_rf <- deffK(muestra %>% 
        filter(R ==1) %>%
        select(w_nr_rf) %>% 
        pull())
deffK_w_nr_rf
```

Una vez ajustados los ponderadores por no respuesta por propensiones simples empleando las estimaciones obtenidas mediante *Random Forest*, el efecto diseño de Kish es de 1,074, que si bien es menor a 1,5, es mayor al valor obtenido luego del ajuste anterior.

```{r}
# Estimaciones empleando ajuste por no respuesta mediante propensiones simples estimadas por random forest

design3 <- muestra %>%
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w_nr_rf)

## Tasa de desempleo
design3 %>% 
  filter(activo == 1) %>% 
  group_by(desocupado) %>% 
  summarise(tasa_desempleo = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

La estimación de la tasa de desempleo al ajustar los ponderadores mediante propensiones simples estimadas por RF es del 8,2% aproximadamente, disminuyendo en comparación a la estimación realizada con los ponderadores ajustados mediante clases de no respuesta. Se destaca además un aumento del efecto diseño, que ahora es de 1,12 en comparación al de 1,09 del ajuste anterior.

```{r}
## Proporción de personas pobres
design3 %>% 
  group_by(pobreza) %>% 
  summarise(prop_pobres = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

Considerando ambos ajuste por no respuesta realizados hasta el momento, la estimación de la proporción de personas pobres resulta muy similar, siendo la primera realizada 0,0837 y 0,0834 con el último ajuste considerado. En este caso el efecto diseño cuando se ajusta con propensiones simples y estimadas por RF se eleva a 2,99, en comparación al valor del ajuste anterior; 2,92.

```{r}
## Ingreso promedio
design3 %>% 
  summarise(ingreso_prom = survey_mean(ingreso, deff = TRUE, vartype = c('se','cv')))
```

La estimación puntual del ingreso promedio considerando el último ajuste realizado es 21491, en comparación a 21686 de la estimación bajo el ajuste por clases de no respuesta. El efecto diseño sigue siendo menor a 1, pero aumenta a 0,949 en el ajuste mediante propensiones simples estimadas por RF. Por otro lado, el desvío estimado disminuye en el caso del último ajuste, siendo de 236,5 en comparación a 238,2.

## Ajuste por no respuesta creando clases de no respuesta, utilizando las propensiones estimadas en el punto anterior.

Este tipo de ajuste tiene la intención de hacer más estables las estimaciones finales de la respuesta. Para realizarlo se forman grupos de unidades de la muestra en base a las propensiones estimadas, en nuestro caso creamos clases en base a los quintiles de las propensiones. Una vez se cuenta con los grupos, se resumen los valores de las propensiones dentro de los mismo para contar con un valor representante dentro de la clase, con la mediana o la media (se opta por esta última). 

```{r}
quintiles_phi <- quantile(muestra$prop_rf, c(0.2, 0.4, 0.6 , 0.8, 1))

muestra <- muestra %>% 
  mutate(
    clase_nr_rf = case_when(
      prop_rf <=  quintiles_phi[1] ~ 1,
      prop_rf > quintiles_phi[1] & prop_rf <= quintiles_phi[2] ~ 2,
      prop_rf > quintiles_phi[2] & prop_rf <= quintiles_phi[3] ~ 3,
      prop_rf > quintiles_phi[3] & prop_rf <= quintiles_phi[4] ~ 4,
      prop_rf > quintiles_phi[4] ~ 5,
    ) %>%  as.factor()
  )

post_estratos_rf <- muestra %>% 
  group_by(clase_nr_rf) %>% 
  summarise(prop_clase_rf = mean(prop_rf))
  
muestra <- muestra %>% 
  mutate(
    prop_clase_rf =  case_when(
      clase_nr_rf == 1 ~ post_estratos_rf$prop_clase_rf[1],
      clase_nr_rf == 2 ~ post_estratos_rf$prop_clase_rf[2],
      clase_nr_rf == 3 ~ post_estratos_rf$prop_clase_rf[3],
      clase_nr_rf == 4 ~ post_estratos_rf$prop_clase_rf[4],
      clase_nr_rf == 5 ~ post_estratos_rf$prop_clase_rf[5]
    ),
  w_post_nr_rf = w0/prop_clase_rf  
  )
```


```{r}
# Efecto diseño de Kish
deffK_post_nr_rf <- deffK(muestra %>% 
        filter(R ==1) %>%
        select(w_post_nr_rf) %>% 
        pull())
deffK_post_nr_rf
```

El efecto diseño en este caso es de 1,067, con lo que al ser menor a 1,5 esto indicaría que el ajuste realizado parece no haber generado valores extremos de los ponderadores. Este valor es menor al obtenido en el ajuste por propensiones simples, pero mayor que el del ajuste por clases de no respuesta.

```{r}
# Estimaciones empleando clases de no respuesta en base a propensiones estimadas por RF

design4 <- muestra %>%
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w_post_nr_rf)

## Tasa de desempleo
design4 %>% 
  filter(activo == 1) %>% 
  group_by(desocupado) %>% 
  summarise(tasa_desempleo = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

Luego de realizar el ajuste se aprecia que la estimación puntual de la tasa de desempleo es la menor de las tres estimadas, siendo del 8,12%. El efecto diseño es 1,1; el valor se ubican entre los dos obtenidos con los otros ajustes. El coeficiente de variación se encuentra entre los otros dos estimados para esta variable de interés.

```{r}
## Proporción de personas pobres
design4 %>% 
  group_by(pobreza) %>% 
  summarise(prop_pobres = survey_mean(deff = TRUE, vartype = c('se','cv')))
```

La proporción de personas pobres también es la menor entre las obtenidas luego de los distintos ajustes. El efecto diseño y coeficiente de variación en este caso se encuentra entre los de los estimados luego de los otros ajustes. 

```{r}
## Ingreso promedio
design4 %>% 
  summarise(ingreso_prom = survey_mean(ingreso, deff = TRUE, vartype = c('se','cv')))
```

La estimación puntual del ingreso en este caso está entre las otras dos anteriores, lo mismo que el efecto diseño y el coeficiente de variación.

\newpage

# Parte 3
### Calibración de los ponderadores

Para seleccionar cuál de los ponderadores ajustados por no respuesta utilizaremos para la calibración, tomamos como criterio seleccionar el que compute el deff mas chico.

*(Ver si los deff estan bien calculados o se calculan con los respondentes)*

```{r}
data<- data.frame(deffK_w_nr_post, deffK_w_nr_rf, deffK_post_nr_rf)
colnames(data)[1]<- "postest-NR"
colnames(data)[2]<- "NR-RF"
colnames(data)[3]<- "postest-NR-RF"
data
```

El ajuste por no respuesta que computa el deff mas pequeño son los ponderadores ajustados por clases de no respuesta.

### Conteos poblacionales de las tres variables auxiliares

Previo a la calibración post estratificada imcompleta (raking), calculamos el verdadero conteo poblacional de las tres variables poblacionales para luego contrastar con el tamaño estimado.

```{r, include=FALSE}
library(readxl)
total_dpto <- read_excel("datos/proyecciones de población por dpto.xlsx")

sexo_y_edades_simples <- read_excel("datos/proyecciones de población por sexo y edades simples.xlsx")

sexo_y_edades_simples <- sexo_y_edades_simples %>% 
  mutate(edad = cut(edad, breaks=c(0, 14,20,25,30,40,50,60,Inf), right = FALSE))

sexo_y_edades_simples <- sexo_y_edades_simples %>%  pivot_longer(names_to="sexo", cols=c("hombres","mujeres"),values_to = "Freq")

sexo_y_edades_simples$sexo <-ifelse(sexo_y_edades_simples$sexo=="hombres",1,2)

sexo_y_edades_simples$sexo <- as.factor(sexo_y_edades_simples$sexo)

pop_count_sexo <- sexo_y_edades_simples %>% group_by(sexo) %>% summarise(Freq=sum(Freq))

pop_count_edad = sexo_y_edades_simples %>% group_by(edad) %>% summarise(Freq=sum(Freq))

pop_count_dpto = total_dpto 

pop_count_dpto$dpto <- as.factor(pop_count_dpto$dpto)

pop_count_dpto <-pop_count_dpto %>%  rename(Freq=personas)

pop_count_dpto$Freq <- as.integer(pop_count_dpto$Freq)
```

```{r,include=TRUE}
pop_count_dpto
```

```{r,include=TRUE}
pop_count_edad
```

```{r,include=TRUE}
pop_count_sexo
```

Visualización de los post-estratos con las variables auxiliares para ver si explican a la variable de interés.

```{r,include=TRUE, echo=FALSE, fig.height=3, fig.width=5}
ggplot(muestra, aes(x=ingreso, y=edad, fill=edad))+ geom_boxplot() + theme_minimal() +theme(legend.position = "none") 
```

Al hacer la visualización de los datos con la variable edad, vemos que ésta no explica la variabilidad de los datos. Se podía decir que sí lo hace en el tramo de edad de 14 a 30 años, pero no lo hace en los tramos de 30 y 60 años, dando a entender que todas las personas entre dichas edades comprendidas  tienen igual ingreso. Por lo tanto, la variable auxilar edad no es útil para mejorar las estimaciones. 

```{r,include=TRUE, echo=FALSE, fig.height=3, fig.width=5}
ggplot(muestra, aes(x=ingreso, y=dpto, fill=dpto))+ geom_boxplot()+ theme_minimal()+ theme(legend.position = "none")
```

En la visualización de la variable departamento podemos notar capta un poco mas la variabilidad e los datos pero no de forma notoria. El que mayor capta la variabilidad de los datos es el departamento de Montevideo. 

```{r,include=TRUE, echo=FALSE, fig.height=3, fig.width=5}
ggplot(muestra, aes(x=ingreso, y=sexo, fill=sexo))+ geom_boxplot() + theme_bw()
```

Por último, el sexo sí es útil para explicar la ingreso de la persona. Si la persona es hombre tiene valor 1 y su ingreso es mayor a que si la persona fuera mujer.
 
### Muestra 

Para la muestra seleccionada, usaremos como ponderadores los ajustados por clases de no respuesta.

### Diseño muestral 

```{r}
diseño <- muestra %>%
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w_nr_post)
```

### Post estratificación incompleta raking con las variables auxiliares edad, sexo y departamento de la forma tradicional

```{r}
rake1=rake(design=diseño, 
           sample.margins=list(~sexo,~edad,~dpto), 
           population.margins=list(pop_count_sexo,
                                   pop_count_edad,
                                   pop_count_dpto))
```

```{r}
svytotal(~sexo,rake1)
svytotal(~edad,rake1)
svytotal(~dpto,rake1)
```

```{r}
muestra = muestra  %>%
  filter(R==1)%>% mutate(g_rake1=weights(rake1)/w_nr_post)

ajuste1 = muestra %>%
  filter(R==1)%>% mutate(g_rake1=weights(rake1)/w_nr_post) %>%  group_by(sexo) %>% summarise(ajustes1=mean(g_rake1))

ajuste2 = muestra %>%
  filter(R==1)%>% mutate(g_rake1=weights(rake1)/w_nr_post) %>%  group_by(dpto) %>% summarise(ajustes2=mean(g_rake1))

ajuste3 = muestra %>%
  filter(R==1)%>% mutate(g_rake1=weights(rake1)/w_nr_post) %>%  group_by(edad) %>% summarise(ajustes3=mean(g_rake1))
```

```{r}
mean(muestra$g_rake1)
```

```{r,include=TRUE, echo=FALSE, fig.height=3, fig.width=4}
ggplot(muestra, aes(x=g_rake1)) +geom_histogram(fill='blue',color='white',alpha=0.3)+theme_bw()
```

Al verificar si los ponderadores calibrados cumple con la ecuación de calibración, podemos notar que sí lo hacen. Con la variable departamento lo hacen al valor exacto sin error, mientra que a la variable edad y sexo lo hacen con un error muy pequeño cercano a cero. 

### Post estratificación incompleta raking con las variables auxiliares edad, sexo y departamento usando la función calibrate

```{r}
counts=c(sum(pop_count_sexo$Freq),
         pop_count_dpto$Freq[-1],
         pop_count_sexo$Freq[-1],
         pop_count_edad$Freq[-1])
```

```{r}
r2=calibrate(design=diseño, 
            formula=~dpto+sexo+edad,
            population=counts,
            calfun="raking")
```

```{r}
svytotal(~sexo,r2)
svytotal(~edad,r2)
svytotal(~dpto,r2)
```

```{r}
muestra = muestra  %>%
  filter(R==1)%>% mutate(g_r2=weights(r2)/w_nr_post)
```

```{r,include=TRUE, echo=FALSE, fig.height=3, fig.width=4}
ggplot(muestra, aes(x=g_r2)) +geom_histogram(fill='blue',color='white',alpha=0.3)+theme_bw()
```

```{r}
mean(muestra$g_r2)
```

Al computar los ponderadores con la función raking, podemos notar que estima los valores poblacionales sin margen de error en las tres variables. 

# Parte 4

```{r}
#Calculo los ponderadores finales ajustados por no respuesta y calibrados 
muestra <- muestra %>% 
  mutate(w_nr_calibrados = w_nr_post*g_rake1)

design_final <- muestra %>% 
  filter(R==1) %>% 
  as_survey_design(ids = id_hogar, strata = estrato, weights = w_nr_calibrados)


set.seed(1)
```

## Estimaciones realizadas con los ponderadores finales ajustados por no respuesta y calibración

```{r}
#Tasa de desempleo
#Al igual que en la parte 1, nos interesan los desempleados considerando el grupo de los activos.
design_final %>%
filter(activo == 1) %>%
group_by(desocupado) %>%
summarise(tasa_desempleo = survey_mean(deff = FALSE, vartype=NULL))
```

Tenemos que la estimación puntual de la tasa de desempleo utilizando los ponderadores ajustados por no respuesta y calibrados es 0.0828, respecto a la tasa de 0.0824 que habíamos obtenido en la parte 1.

```{r}
#Proporción de personas pobres
design_final %>%
group_by(pobreza) %>%
summarise(prop_pobres = survey_mean(deff = FALSE, vartype=NULL))
```

La proporción de personas pobres estimada con los ponderadores finales es de 0.0766, mientras que la estimación realizada en la parte 1 era de 0.0811.

```{r}
## Ingreso promedio
design_final %>%
summarise(ingreso_prom = survey_mean(ingreso, vartype=NULL))
```

La estimación puntual del ingreso promedio para el total país realizada con los ponderadores finales es de 21597, inferior al 21799 estimado en la parte 1.


## Estimaciones realizadas a nivel departamental

```{r}
#Tasa de desempleo
#Al igual que en la parte 1, nos interesan los desempleados considerando el grupo de los activos.
design_final %>%
filter(activo == 1) %>%
group_by(desocupado, dpto) %>%
summarise(tasa_desempleo = survey_mean(deff = FALSE, vartype=c("se", "cv", "ci"), level=0.95)) %>%
filter(desocupado==1) %>% 
  arrange(desc(tasa_desempleo))
```

Realizamos la estimación de la tasa de desempleo, con su correspondiente error estándar, coeficiente de variación e intervalo de confianza al 95% para los distintos departamentos. Podemos ver que el departamento con una mayor tasa de desempleo es Montevideo con 0.0362, aunque también es el que tiene un mayor SE de 0.0203.

```{r}
#Proporción de personas pobres
design_final %>%
group_by(pobreza, dpto) %>%
summarise(prop_pobres = survey_mean(deff = FALSE, vartype=c("se", "cv", "ci"), level=0.95)) %>%
filter(pobreza==1) %>% 
  arrange(desc(prop_pobres))
```

Para la proporción de personas pobres sucede algo similar, el departamento con mayor proporción de pobreza estimada es Montevideo con 0.495, estimación puntual que resulta excesivamente alta, y también tiene el mayor desvío estándar de 0.0244. El intervalo de confianza de la proporción de pobreza para este departamento es $(0.447, 0.543)$, que resulta en valores altos al igual que la estimación puntual. Hay una diferencia sustancial respecto al segundo departamento, con mayor proporción de pobreza estimada, que tiene una estimación puntual de 0.0942. Aquel que tiene la menor pobreza estimada, por su parte, tiene un intervalo de confianza que llega a tomar valores negativos, lo cual no tiene sentido desde el punto de vista interpretativo.


```{r}
## Ingreso promedio
design_final %>%
  group_by(dpto) %>% 
summarise(ingreso_prom = survey_mean(ingreso, vartype=c("se", "cv", "ci"), level=0.95)) %>% 
  arrange(desc(ingreso_prom))

```

Para la estimación del ingreso promedio a nivel de departamentos, tenemos nuevamente que el departamento con mayor ingreso promedio es Montevideo con 29188, si bien tiene el menor error estándar de 535.

## Cálculo del error estándar a partir del método del último conglomerado y Bootstrap Rao Wu

A continuación compararemos los errores estándar calculados anteriormente a nivel departamento utilizando el método del último conglomerado que utiliza por defecto el paquete survey, con los calculados utilizando Bootstrap Rao Wu.


```{r}
#Al igual que en la parte 1, nos interesan los desempleados considerando el grupo de los activos.

#Tasa de desempleo

reps <- 500

tasa_desempleo_survey <- design_final %>%
filter(activo == 1) %>%
group_by(desocupado) %>%
summarise(tasa_desempleo = survey_mean(deff = FALSE)) %>% 
  filter(desocupado==1) %>% 
  mutate(dpto="pais") %>% 
  select(-"desocupado")


#Tasa de desempleo con SE estimado por bootstrap rao wu

tasa_desempleo_boot <- 
design_final %>%
  filter(activo==1) %>%
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>%
  svymean(~desocupado, .) %>% 
  as.data.frame() %>% 
  mutate(dpto="pais") %>% 
  subset(., rownames(.) %in% "desocupado1") %>% 
  `rownames<-`( NULL ) %>% 
  rename(tasa_desempleo_boot="mean", tasa_desempleo_se_boot="SE")


tasa_desempleo_survey_dptos <- design_final %>%
  filter(activo == 1) %>%
  group_by(desocupado, dpto) %>%
  summarise(tasa_desempleo = survey_mean(deff = FALSE)) %>% 
  filter(desocupado==1) %>% 
  as.data.frame() %>% 
  select(-"desocupado")


tasa_desempleo_boot_dptos <- 
  design_final %>%
  filter(activo==1) %>%
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>% 
  svyby(~desocupado, ~dpto, design=., svymean) %>% 
  as.data.frame() %>% 
  select(dpto , desocupado1, se1) %>% 
  `rownames<-`( NULL ) %>% 
  rename(tasa_desempleo_boot="desocupado1", tasa_desempleo_se_boot="se1")





rbind(
  left_join(tasa_desempleo_survey, tasa_desempleo_boot, by="dpto") %>% 
    relocate(dpto, tasa_desempleo, tasa_desempleo_boot, tasa_desempleo_se, tasa_desempleo_se_boot),
  left_join(tasa_desempleo_survey_dptos, tasa_desempleo_boot_dptos, by="dpto") %>% 
    relocate(dpto, tasa_desempleo, tasa_desempleo_boot, tasa_desempleo_se, tasa_desempleo_se_boot)
) 
  
```

Con la estimación del error estándar realizada por el método del último conglomerado, el SE estimado a nivel país es 0.00338, mientras que el SE estimado a través de Bootstrap Rao Wu es 0.0032.

Basándonos en el SE estimado por el método del último conglomerado, tenemos que la estimación del coeficiente de variación (CV) es 0.0408, y que el intervalo de confianza estimado al 95% es $(0.0762, 0.0894)$.


```{r}
#Proporción de personas pobres
prop_pobres_survey <- 
design_final %>%
group_by(pobreza) %>%
summarise(prop_pobres = survey_mean(deff = FALSE)) %>% 
  filter(pobreza==1) %>% 
  mutate(dpto="pais") %>% 
  select(-"pobreza")



prop_pobres_boot <-
  design_final %>%
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>% 
  svymean(~pobreza, .) %>% 
  as.data.frame() %>% 
  mutate(dpto="pais") %>% 
  subset(., rownames(.) %in% "pobreza1") %>% 
  `rownames<-`( NULL ) %>% 
  rename(prop_pobreza_boot="mean", prop_pobreza_se_boot="SE")


prop_pobres_survey_dptos <- 
design_final %>%
group_by(pobreza, dpto) %>%
summarise(prop_pobres = survey_mean(deff = FALSE)) %>% 
  filter(pobreza==1) %>% 
  as.data.frame() %>% 
  select(-"pobreza")


prop_pobres_boot_dptos <-
  design_final %>%
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>% 
  svyby(~pobreza, ~dpto, design=., svymean) %>% 
  as.data.frame() %>% 
  select(dpto, pobreza1, se1) %>% 
  `rownames<-`( NULL ) %>% 
  rename(prop_pobreza_boot="pobreza1", prop_pobreza_se_boot="se1")

rbind(
  left_join(prop_pobres_survey, prop_pobres_boot, by="dpto") %>% 
    relocate(dpto, prop_pobres, prop_pobres_se, prop_pobreza_boot , prop_pobreza_se_boot),
  left_join(prop_pobres_survey_dptos, prop_pobres_boot_dptos, by="dpto") %>% 
    relocate(dpto, prop_pobres, prop_pobres_se, prop_pobreza_boot , prop_pobreza_se_boot)
) 


```

La estimación del SE realizada con el método del último conglomerado es 0.00365, mientras que la realizada con Bootstrap Rao Wu es 0.0038.

Tomando como base el error estándar calculado con el método del último conglomerado, tenemos que el coeficiente de variación estimado es 0.0476, y que el intervalo de confianza estimado al 95% para la proporción de personas pobres es $(0.0695, 0.0838)$.

```{r}
## Ingreso promedio
ingreso_promedio_survey <- 
  design_final %>%
summarise(ingreso_prom = survey_mean(ingreso)) %>% 
  mutate(dpto="pais")

ingreso_promedio_boot <-
  design_final %>% 
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>% 
  svymean(~ingreso, design=.)  %>% 
  as.data.frame() %>% 
  mutate(dpto="pais") %>% 
  as.data.frame %>%
  `rownames<-`( NULL ) %>% 
  rename(ingreso_promedio_boot="mean", ingreso_promedio_se_boot="SE")
  

ingreso_promedio_survey_dptos <- 
  design_final %>%
  group_by(dpto) %>% 
  summarise(ingreso_prom = survey_mean(ingreso))


ingreso_promedio_boot_dptos <-
  design_final %>% 
  as.svrepdesign(design=., type="subbootstrap", replicates=reps) %>% 
  svyby(~ingreso, ~dpto, design=., svymean) %>% 
  as.data.frame() %>% 
  `rownames<-`( NULL ) %>% 
  rename(ingreso_promedio_boot="ingreso", ingreso_promedio_se_boot="se")


rbind(
  left_join(ingreso_promedio_survey, ingreso_promedio_boot, by="dpto") %>% 
    relocate(dpto, ingreso_prom, ingreso_promedio_boot, ingreso_prom_se, ingreso_promedio_se_boot),
  left_join(ingreso_promedio_survey_dptos, ingreso_promedio_boot_dptos, by="dpto") %>% 
    relocate(dpto, ingreso_prom, ingreso_promedio_boot, ingreso_prom_se, ingreso_promedio_se_boot)
) 

```

Se calcula el error estándar del estimador utilizando dos métodos distintos. A partir del método del último conglomerado la estimación del SE es 248, mientras que la estimación realizada con Bootstrap Rao Wu es de 246.68.

Partiendo del SE calculado con el método del último conglomerado, tenemos que un intervalo de confianza al 95% estimado para el ingreso promedio es $(21111, 22082)$, mientras que el coeficiente de variación estimado es de 0.0115.
